# Auth
AUTH_TOKEN=demo-key

# Modelle
MODEL_NAME=llama3.2           # genau wie in `ollama list`
EMBED_MODEL=nomic-embed-text  # oder bge-m3, je nachdem was du gepullt hast

# Retrieval
RAG_TOPK=12
RAG_RETURN=5
RAG_MMR_LAMBDA=0.5
RAG_MAX_CTX_TOKENS=1500

# LLM Optionen
NUM_CTX=3072
TEMPERATURE=0.2

# Services (werden in Docker-Netzwerk aufgel√∂st)
OLLAMA_URL=http://ollama:11434
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=docs
